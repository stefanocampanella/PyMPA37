#! /usr/bin/env python
import argparse
import logging
import os
import sys
from pathlib import Path
from datetime import datetime

from tqdm import tqdm
import pandas as pd

from pympa.pympa import read_templates, read_continuous_stream, correlation_detector

parser = argparse.ArgumentParser(prog="PyMPA37",
                                 description="A software package for phase match filtering")
parser.add_argument("root", help="Working directory", type=Path, nargs='?', default=os.getcwd())
parser.add_argument("date", help="Datetime begin", type=datetime.fromisoformat)
parser.add_argument("output", help="Output file path")
parser.add_argument("--min_channels", help="Minimum number of channels", type=int, default=6)
parser.add_argument("--max_channels", help="Maximum number of channels", type=int, default=15)
parser.add_argument("--lowpass_freq", help="Lowpass filter frequency", type=float, default=3.0)
parser.add_argument("--highpass_freq", help="Highpass filter frequency", type=float, default=8.0)
parser.add_argument("--threshold_factor", help="Factor for the mean correlation peak MAD threshold",
                    type=float, default=8.0)
parser.add_argument("--min_correlation_std", help="Minimum correlation std", type=float, default=0.25)
parser.add_argument("--max_correlation_std", help="Maximum correlation std", type=float, default=1.5)
parser.add_argument("--cc_filter_num_channels", help="Minimum number of channels with correlation above threshold",
                    type=int, default=6)
parser.add_argument("--cc_filter_threshold", help="Correlation threshold per channels", type=float, default=0.35)
parser.add_argument("--sample_tolerance", help="Maximum lag in samples", type=int, default=6)
parser.add_argument("--travel_times", help="Relative path to travel times directory", type=Path, default='travel_times')
parser.add_argument("--templates", help="Relative path to templates directory", type=Path, default='templates')
parser.add_argument("--catalog", help="Relative path to event catalog", type=Path, default='templates.zmap')
parser.add_argument("--continuous", help="Relative path to continuous traces directory", type=Path, default='24h')
cli_args = parser.parse_args()

logging.basicConfig(stream=sys.stderr,
                    format='%(levelname)s: %(message)s',
                    level=logging.ERROR)

if __name__ == '__main__':
    is_interactive = os.isatty(sys.stdout.fileno())

    templates = read_templates(cli_args.root / cli_args.templates,
                               cli_args.root / cli_args.travel_times,
                               cli_args.root / cli_args.catalog,
                               cli_args.min_channels,
                               cli_args.max_channels)

    events = []
    day_stream = read_continuous_stream(cli_args.continuous,
                                        cli_args.date,
                                        cli_args.min_channels,
                                        freqmin=cli_args.lowpass_freq,
                                        freqmax=cli_args.highpass_freq)
    for template_number, template_stream, travel_times, template_magnitude in tqdm(templates,
                                                                                   disable=not is_interactive):
        try:
            detections = correlation_detector(template_stream,
                                              day_stream,
                                              travel_times,
                                              template_magnitude,
                                              cli_args.threshold_factor,
                                              cli_args.sample_tolerance,
                                              (cli_args.min_correlation_std, cli_args.max_correlation_std))
            for detection in detections:
                date, magnitude, correlation, stack_height, stack_dmad, channels = detection
                num_channels = sum(1 for _, cc, _ in channels if cc > cli_args.cc_filter_threshold)
                if num_channels >= cli_args.cc_filter_num_channels:
                    record = (template_number, date.datetime, magnitude, correlation,
                              stack_height, stack_dmad, num_channels)
                    events.append(record)
        except ValueError as err:
            logging.info(f"{err} occurred during processing of template {template_number}, {cli_args.date}")

    events_dataframe = pd.DataFrame.from_records(events,
                                                 columns=['template', 'date', 'magnitude',
                                                          'correlation', 'stack_height', 'stack_dmad',
                                                          'num_channels'])
    events_dataframe.sort_values(by=['template', 'date'], inplace=True)
    events_dataframe['crt_pre'] = events_dataframe['stack_height'] / events_dataframe['stack_dmad']
    events_dataframe['crt_post'] = events_dataframe['correlation'] / events_dataframe['stack_dmad']
    logging.info(f"Writing outputs to {cli_args.output}")
    events_dataframe.to_csv(cli_args.output,
                            index=False,
                            date_format='%Y-%m-%dT%H:%M:%S.%fZ',
                            float_format='%.3f',
                            columns=['template', 'date', 'magnitude',
                                     'correlation', 'crt_post',
                                     'stack_height', 'crt_pre',
                                     'num_channels'],
                            header=False, sep=' ')
