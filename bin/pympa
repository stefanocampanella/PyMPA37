#! /usr/bin/env python
import argparse
import logging
import os
import sys
from pathlib import Path
from datetime import datetime

from yaml import load, FullLoader
from tqdm import tqdm
import pandas as pd

from pympa.pympa import read_templates, range_days, read_continuous_stream, correlation_detector

parser = argparse.ArgumentParser(prog="PyMPA37",
                                 description="A software package for phase match filtering")
parser.add_argument("travel_times_dir_path", help="Path to travel times directory", type=Path)
parser.add_argument("templates_dir_path", help="Path to templates directory", type=Path)
parser.add_argument("catalog_path", help="Path to event catalog", type=Path)
parser.add_argument("continuous_dir_path", help="Path to continuous traces directory", type=Path)
parser.add_argument("begin_date", help="Datetime begin", type=datetime.fromisoformat)
parser.add_argument("end_date", help="Datetime end", type=datetime.fromisoformat)
parser.add_argument("output_path", help="Output file path")
cli_args = parser.parse_args()

logging.basicConfig(stream=sys.stderr,
                    format='%(levelname)s: %(message)s',
                    level=logging.ERROR)

if __name__ == '__main__':
    is_interactive = os.isatty(sys.stdout.fileno())

    with open("settings.yaml") as settings_file:
        settings = load(settings_file, FullLoader)

    templates = read_templates(cli_args.templates_dir_path, cli_args.travel_times_dir_path, cli_args.catalog_path,
                               settings['templates']['num_channels_min'],
                               num_templates_bounds=settings['templates']['range'],
                               num_tt_channels_bounds=settings['travel_times']['num_channels_bounds'])

    events = []
    for day in tqdm(range_days(cli_args.begin_date, cli_args.end_date),
                    total=(cli_args.end_date - cli_args.begin_date).days,
                    disable=not is_interactive):
        day_stream = read_continuous_stream(cli_args.continuous_dir_path,
                                            day,
                                            settings['continuous']['num_channels_min'],
                                            freqmin=settings['continuous']['lowpass_freq'],
                                            freqmax=settings['continuous']['highpass_freq'])
        for template_number, template_stream, travel_times, template_magnitude in tqdm(templates, leave=False,
                                                                                       disable=not is_interactive):

            detections = correlation_detector(template_stream,
                                              day_stream,
                                              travel_times,
                                              template_magnitude,
                                              settings['detector']['threshold_factor'],
                                              settings['detector']['samples_tolerance'],
                                              correlations_std_bounds=settings['detector']['correlations_std_bounds'])
            for detection in detections:
                date, magnitude, correlation, stack_height, stack_dmad, channels = detection
                num_channels = sum(1 for _, cc, _ in channels if cc > settings['cc_filter']['threshold'])
                if num_channels >= settings['cc_filter']['num_channels']:
                    record = (template_number, date.datetime, magnitude, correlation,
                              stack_height, stack_dmad, num_channels)
                    events.append(record)
    events_dataframe = pd.DataFrame.from_records(events,
                                                 columns=['template', 'date', 'magnitude',
                                                          'correlation', 'stack_height', 'stack_dmad',
                                                          'num_channels'])
    events_dataframe.sort_values(by=['template', 'date'], inplace=True)

    output_path = Path(cli_args.output_path)
    logging.info(f"Writing outputs to {output_path}")
    events_dataframe['crt_pre'] = events_dataframe['stack_height'] / events_dataframe['stack_dmad']
    events_dataframe['crt_post'] = events_dataframe['correlation'] / events_dataframe['stack_dmad']
    events_dataframe.to_csv(output_path, index=False,
                            date_format='%Y-%m-%dT%H:%M:%S.%fZ',
                            float_format='%.3f',
                            columns=['template', 'date', 'magnitude',
                                     'correlation', 'crt_post',
                                     'stack_height', 'crt_pre',
                                     'num_channels'],
                            header=False, sep=' ')
